import sys

import os
import gi

gi.require_version('Gst', '1.0')
from gi.repository import Gst
Gst.init(None)

import os
from pathlib import Path

from PySide6.QtWidgets import (QLabel, QSizePolicy, QVBoxLayout, QHBoxLayout, QWidget, QApplication, QMainWindow, QMenu, QGraphicsDropShadowEffect)
from PySide6.QtGui import QImage, QPainter, QPen, QColor, QPolygon, QBrush, QMouseEvent, QPixmap, QAction, QDesktopServices, QGuiApplication
from PySide6.QtCore import Qt, QThread, Signal, QPoint, QObject, QEvent, QTimer, QPropertyAnimation, QEasingCurve, QRect, QSize, QUrl
import cv2
import numpy as np
import requests
import random
from datetime import datetime, timezone, timedelta
import json

import smtplib
from email.mime.text import MIMEText
from email.mime.image import MIMEImage
from email.mime.multipart import MIMEMultipart
from email.header import Header
import base64

import time
import threading
import queue

import webbrowser
from cryptography.fernet import Fernet
import traceback
import subprocess

ROOT = Path(__file__).resolve().parents[1]
COLOR = {
    0: (0, 150, 95),     # Grass Green - person
    1: (0, 242, 255),    # yellow - bicycle (ë³€ê²½)
    2: (180, 130, 70),   # Steel Blue - car
    3: (0, 140, 255),    # Dark Orange - motorcycle
    4: (219, 112, 147),  # Medium Purple - bus
    5: (204, 209, 72),   # Medium Turquoise - truck
    6: (147, 20, 255),   # Deep Pink - fire
}

class Video_Buffer:
    def __init__(self, pipe="video1", appsink_name="video_sink", resolution=(640,480), chg_fps_mode = False, fps = 30):
        self._frame = None
        self.connection_status = True  # RTSP ì—°ê²° ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ë³€ìˆ˜
        self.video_source = f'rtspsrc location=rtsp://{pipe} latency=10 buffer-mode=0 protocols=tcp'
        print(self.video_source)
        if chg_fps_mode == True:
            self.video_codec = '! rtph264depay ! h264parse '  # 'application/x-rtp' ìƒëµ
            self.video_decode = f'! decodebin ! videorate ! capsfilter name=capsfilter0 caps=video/x-raw,framerate={fps}/1 ! videoscale ! video/x-raw,width={resolution[0]},height={resolution[1]} ! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=1 drop=true'
            # self.video_decode = f'! nvh264dec ! videorate ! capsfilter name=capsfilter0 caps=video/x-raw,framerate={fps}/1 ! videoscale ! video/x-raw,width={resolution[0]},height={resolution[1]} ! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=1 drop=true'

        else:
            self.video_codec = '! application/x-rtp, encoding-name=(string)H264, payload=96 ! rtph264depay ! h264parse '
            # self.video_decode = f'! decodebin ! videoscale ! video/x-raw,width={resolution[0]},height={resolution[1]} ! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=3 drop=true'
            # self.video_decode = f'! decodebin ! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=1 drop=true'
            # self.video_decode = f'! nvh264dec ! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=1 drop=true'
            # self.video_decode = f'! decodebin ! videoconvert ! video/x-raw,format=(string)BGR ! videoconvert ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=3 drop=true'
            self.video_decode = f'! decodebin ! videorate ! capsfilter name=capsfilter0 caps=video/x-raw ! videoscale ! video/x-raw,width={resolution[0]},height={resolution[1]} ! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={appsink_name} emit-signals=true sync=false max-buffers=5 drop=true'

        self.video_pipe = None
        self.video_sink = None
        self.appsink_name = appsink_name
        self.run()

    def start_gst(self, config=None):
        if not config:
            config = [
                'videotestsrc ! decodebin',
                f'! videoconvert ! video/x-raw,format=(string)BGR ! appsink name={self.appsink_name}'
            ]

        command = ' '.join(config)
        try:
            self.video_pipe = Gst.parse_launch(command)
        except:
            self.video_pipe = Gst.parse_launch(command)

        self.video_pipe.set_state(Gst.State.PLAYING)
        self.video_sink = self.video_pipe.get_by_name(self.appsink_name)
        
        if not self.video_sink:
            print(f"Failed to get appsink named {self.appsink_name}")
            return
        
        self.video_sink.set_property("emit-signals", True)
        self.video_sink.set_property("sync", False)

    @staticmethod
    def gst_to_opencv(sample):
        buf = sample.get_buffer()
        caps = sample.get_caps()
        array = np.ndarray(
            (
                caps.get_structure(0).get_value('height'),
                caps.get_structure(0).get_value('width'),
                3
            ),
            buffer=buf.extract_dup(0, buf.get_size()), dtype=np.uint8)
        return array

    def read(self):
        if self.frame_available():
            return self.frame_available(), self._frame
        else:
            return self.frame_available(), np.zeros((640, 480, 3), dtype=np.uint8)
        
    def frame_available(self):
        # ì—°ê²° ìƒíƒœë¥¼ ë¨¼ì € í™•ì¸í•˜ê³ , ëŠê²¨ìˆìœ¼ë©´ Falseë¥¼ ë¦¬í„´
        if not self.connection_status:
            return False
        return self._frame is not None

    def run(self):
        try:
            self.start_gst(
                [
                    self.video_source,
                    self.video_codec,
                    ' ! queue leaky=downstream max-size-buffers=10 ',
                    self.video_decode
                ]
            )

            if self.video_sink:
                self.video_sink.connect('new-sample', self.callback)

            bus = self.video_pipe.get_bus()
            bus.add_signal_watch()
            bus.connect("message", self.on_message)
        except Exception as e:
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            tb = traceback.format_exc()
            print(f"Error occurred at {current_time}: {e}\n{tb}", file=sys.stderr)

    def on_message(self, bus, message):
        t = message.type
        if t == Gst.MessageType.ERROR or t == Gst.MessageType.EOS:
            self.connection_status = False  # ì—°ê²° ìƒíƒœë¥¼ Falseë¡œ ì„¤ì •
            print(f"Error or EOS detected. Reconnecting...")

            if self.video_pipe:
                self.video_pipe.set_state(Gst.State.NULL)

            # self.run()  # íŒŒì´í”„ë¼ì¸ì´ NULL ìƒíƒœê°€ ëœ í›„ì— ì¬ì‹œì‘

    def callback(self, sink):
        try:
            sample = sink.emit('pull-sample')
            if sample is None:
                print("No sample received, returning...")
                return Gst.FlowReturn.ERROR  # ì ì ˆí•œ ì˜ˆì™¸ ì²˜ë¦¬ê°€ ì´ë£¨ì–´ì ¸ì•¼ í•¨
            
            new_frame = self.gst_to_opencv(sample)
            self._frame = new_frame

        except Exception as e:
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            tb = traceback.format_exc()
            print(f"Error in callback at {current_time}: {e}\n{tb}", file=sys.stderr)
            return Gst.FlowReturn.ERROR

        return Gst.FlowReturn.OK

    def change_framerate(self, fps):
        """Change the framerate dynamically using capsfilter."""
        if fps == 30:
            fps = 10
        if self.video_pipe:
            # Get the capsfilter element from the pipeline
            capsfilter = self.video_pipe.get_by_name("capsfilter0")
            if capsfilter:
                # Create new caps with the updated framerate
                new_caps = Gst.Caps.from_string(f"video/x-raw,framerate={fps}/1")
                capsfilter.set_property("caps", new_caps)
                # print(f"Framerate changed to {fps} FPS")
            else:
                print("Could not find capsfilter element.")

    def release(self):
        if self.video_pipe:
            self.video_pipe.set_state(Gst.State.NULL)  # íŒŒì´í”„ë¼ì¸ì„ ì¤‘ì§€ ìƒíƒœë¡œ ì„¤ì •
            self.connection_status = False  # ì—°ê²° ìƒíƒœë¥¼ Falseë¡œ ì„¤ì •
            self.video_pipe = None
            # print("RTSP stream stopped.")


class RtspVideoReader:
    """
    íƒ€ì„ì•„ì›ƒ ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ ë¦¬ë”ê¸°.
    cv2.VideoCapture.read()ê°€ ë„¤íŠ¸ì›Œí¬ ë¬¸ì œë¡œ ë©ˆì¶”ëŠ” í˜„ìƒì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    def __init__(self, rtsp_url):
        self.url = rtsp_url
        self.queue = queue.Queue(maxsize=30)  # í”„ë ˆì„ ë²„í¼
        self.cap = None
        self.__thread_active = False
        self.read_thread = None
        
        # ìŠ¤ë ˆë“œ ì‹œì‘
        self.start()

    def _reader_thread(self):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ í”„ë ˆì„ì„ ì½ì–´ íì— ë„£ëŠ” ìŠ¤ë ˆë“œ í•¨ìˆ˜"""
        print(f"[Reader Thread] ìŠ¤ë ˆë“œ ì‹œì‘. {self.url} ì—°ê²° ì‹œë„...")
        self.cap = cv2.VideoCapture(self.url)
        
        if not self.cap.isOpened():
            print(f"[Reader Thread] ì—ëŸ¬: ìŠ¤íŠ¸ë¦¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.queue.put(None)  # ì‹œì‘ ì‹¤íŒ¨ ì‹ í˜¸
            return

        print("[Reader Thread] ìŠ¤íŠ¸ë¦¼ ì—´ê¸° ì„±ê³µ. ì½ê¸° ì‹œì‘.")
        while self.__thread_active:
            # grab() / retrieve() ë°©ì‹ ì‚¬ìš©
            ret_grab = self.cap.grab()
            
            if not ret_grab:
                # ìŠ¤íŠ¸ë¦¼ì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œëœ ê²½ìš°
                print("[Reader Thread] grab()=False. ìŠ¤íŠ¸ë¦¼ì´ ì •ìƒ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
            
            # ê°€ì ¸ì˜¨ í”„ë ˆì„ì„ ë””ì½”ë”©
            ret_retrieve, frame = self.cap.retrieve()
            
            if not ret_retrieve:
                # ë””ì½”ë”© ì‹¤íŒ¨ (ë“œë¬¼ê²Œ ë°œìƒ)
                continue
            
            # íê°€ ê°€ë“ ì°¼ìœ¼ë©´ ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ì„ ë²„ë¦¼
            if self.queue.full():
                try:
                    self.queue.get_nowait()
                except queue.Empty:
                    pass  # í˜¹ì‹œ ëª¨ë¥¼ ë™ì‹œì„± ë¬¸ì œ ë°©ì§€
            
            self.queue.put(frame)
            time.sleep(0.001)  # CPU ê³¼ì ìœ  ë°©ì§€

        # ë£¨í”„ ì¢…ë£Œ ì‹œ (ì •ìƒ ì¢…ë£Œ ë˜ëŠ” stop() í˜¸ì¶œ)
        print("[Reader Thread] ìŠ¤ë ˆë“œ ì¢…ë£Œ ì¤‘...")
        if self.cap:
            self.cap.release()
        self.queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸

    def start(self):
        """ì½ê¸° ìŠ¤ë ˆë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        if self.__thread_active:
            print("[Reader] ì´ë¯¸ ìŠ¤ë ˆë“œê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return
            
        self.__thread_active = True
        self.read_thread = threading.Thread(target=self._reader_thread)
        self.read_thread.daemon = True  # ë©”ì¸ ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹œ í•¨ê»˜ ì¢…ë£Œ
        self.read_thread.start()

    def read(self, timeout=5.0):
        """
        íì—ì„œ í”„ë ˆì„ì„ ì½ì–´ì˜µë‹ˆë‹¤.
        'timeout' ì´ˆ ë™ì•ˆ ìƒˆ í”„ë ˆì„ì´ ì—†ìœ¼ë©´ (False, None)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        try:
            # íƒ€ì„ì•„ì›ƒì„ ê±¸ê³  íì—ì„œ í”„ë ˆì„ì„ ê¸°ë‹¤ë¦¼
            frame = self.queue.get(timeout=timeout)
            
            if frame is None:
                # ìŠ¤ë ˆë“œì—ì„œ ë³´ë‚¸ ì¢…ë£Œ ì‹ í˜¸
                return False, None
                
            return True, frame
        except queue.Empty:
            # íê°€ ë¹„ì–´ìˆê³  'timeout'ì´ ê²½ê³¼í•¨ -> ìŠ¤íŠ¸ë¦¼ì´ ë©ˆì¶˜ ê²ƒìœ¼ë¡œ ê°„ì£¼
            print(f"[Reader] {timeout}ì´ˆ ë™ì•ˆ ìƒˆ í”„ë ˆì„ ì—†ìŒ. íƒ€ì„ì•„ì›ƒ.")
            return False, None

    def stop(self):
        """ì½ê¸° ìŠ¤ë ˆë“œë¥¼ ì¤‘ì§€ì‹œí‚µë‹ˆë‹¤."""
        print("[Reader] ì¤‘ì§€ ì‹ í˜¸ ì „ì†¡...")
        self.__thread_active = False
        
        # íë¥¼ ë¹„ì›Œì„œ ìŠ¤ë ˆë“œê°€ ë©ˆì¶œ ìˆ˜ ìˆê²Œ í•¨
        while not self.queue.empty():
            try:
                self.queue.get_nowait()
            except queue.Empty:
                break
        
        if self.read_thread:
            self.read_thread.join(timeout=1.0)  # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°


class Connect_Camera(QThread):
    # Signal emitted when a new image or a new frame is ready.
    ImageUpdated = Signal(QImage)
    doubleClicked = Signal()

    def __init__(self, pipe, host, port, camera_name, viewer, plot_bbox = True, plot_label = True,  plot_roi = True, roi_thickness = 1, ai_active = False, live_viewer_blcok_active = False) -> None:
        super(Connect_Camera, self).__init__()
        # Declare and initialize instance variables.
        self.pipe = pipe
        self.__thread_active = True
        self.disconnect_cnt = 0
        self.__thread_pause = False
        self.camera_connect_flag = False
        # self.camera_num = camera_num
        self.camera_name = camera_name

        self.ai_active = ai_active

        self.viewer = viewer

        self.host = host
        self.port = port

        self.back_url = f"http://{self.host}:{self.port}/get-camera-ai-plot-data"

        self.roi_thickness = roi_thickness
        self.live_viewer_blcok_active = live_viewer_blcok_active
        # self.live_screen_block_img = cv2.imread(u":/ui/ui/images/ico_video_on.svg")
        self.plot_bbox = plot_bbox
        self.plot_label = plot_label
        self.plot_roi = plot_roi

        self.fps = 30

    def mouseDoubleClickEvent(self, event):
        self.doubleClicked.emit()  # ë”ë¸” í´ë¦­ ì‹œ ì‹œê·¸ë„ ë°œìƒ

    def run(self) -> None:
        self.cap = Video_Buffer(pipe=self.pipe, resolution=(640,480))

        session = requests.Session()
        # While the thread is active.
        t0 = time.time()
        while self.__thread_active:
            
            ret, self.frame_ori = self.cap.read()
            # print(ret)

            if ret == False : 
                if time.time() - t0 > 5:
                    # self.cap.release()
                    # self.cap = cv2.VideoCapture(self.pipe)
                    continue
                
            t0 = time.time()
            self.camera_connect_flag = True
            # If frame is read correctly.
            # self.frame = cv2.resize(self.frame_ori, dsize=(self.viewer.width(), self.viewer.height()))
            self.frame = np.array(self.frame_ori)

            if self.ai_active and  (self.plot_bbox or self.plot_label or self.plot_roi):
                try:
                    receive_data = session.get(self.back_url, json={"msg" : self.camera_name}).json()

                    if receive_data[self.camera_name]:
                        line_thickness = 3 if self.frame.shape[1] == 1920 else 1
                        self.frame = plot_detect_info(img = self.frame, detect_info = receive_data[self.camera_name], line_thickness = line_thickness, roi_thickness = self.roi_thickness, plot_bbox = self.plot_bbox, plot_label = self.plot_label, plot_roi = self.plot_roi)
                except:
                    pass                
            self.disconnect_cnt = 0
            height, width, channels = self.frame.shape
            bytes_per_line = width * channels
            cv_rgb_image = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)

            qt_rgb_image = QImage(cv_rgb_image.data, width, height, bytes_per_line, QImage.Format_RGB888)

            if self.live_viewer_blcok_active:
                # ë¡œê³  ì´ë¯¸ì§€ë¥¼ ë·°ì–´ í¬ê¸°ì— ë§ê²Œ paddingí•˜ì—¬ emit
                width, height = self.viewer.width(), self.viewer.height()
                logo_pixmap = QPixmap(u":/ui/ui/images/logo.png")
                
                # ë·°ì–´ í¬ê¸°ì— ë§ëŠ” ë¹ˆ ìº”ë²„ìŠ¤ ìƒì„± (ê²€ì€ìƒ‰ ë°°ê²½)
                canvas = QPixmap(width, height)
                canvas.fill(Qt.black)
                
                # ë¡œê³ ë¥¼ ìº”ë²„ìŠ¤ ì¤‘ì•™ì— ë°°ì¹˜
                painter = QPainter(canvas)
                x = (canvas.width() - logo_pixmap.width()) // 2
                y = (canvas.height() - logo_pixmap.height()) // 2
                painter.drawPixmap(x, y, logo_pixmap)
                painter.end()
                
                logo_image = canvas.toImage()
                self.ImageUpdated.emit(logo_image)

            else:
                self.ImageUpdated.emit(qt_rgb_image)

            # time.sleep(0.033)
            sleep_time = max(0, (1 / self.fps) - (time.time() - t0))
            time.sleep(sleep_time)

        else:
            self.camera_connect_flag = False

        self.cap.release()
        self.quit()

    def stop(self) -> None:
        self.__thread_active = False
        self.wait()

    def pause(self) -> None:
        self.__thread_pause = True

    def unpause(self) -> None:
        self.__thread_pause = False

class Connect_Playback(QThread):
    # Signal emitted when a new image or a new frame is ready.
    ImageUpdated = Signal(QImage)

    def __init__(self, url, viewers_widget) -> None:
        super(Connect_Playback, self).__init__()
        # Declare and initialize instance variables.
        self.pipe = url
        self.__thread_active = True
        self.fps = 0
        self.disconnect_cnt = 0

        self.viewers_widget = viewers_widget
        self.reader = None

    def run(self) -> None:
        try:
            self.pipe = "rtsp://" + self.pipe
            
            # RtspVideoReader ì‚¬ìš© (íƒ€ì„ì•„ì›ƒ ê¸°ëŠ¥ í¬í•¨)
            self.reader = RtspVideoReader(self.pipe)
            
            t0 = time.time()

            while self.__thread_active:
                # íƒ€ì„ì•„ì›ƒ 5ì´ˆë¡œ í”„ë ˆì„ ì½ê¸°
                ret, self.frame_ori = self.reader.read(timeout=5.0)
                
                # print(f"Playback read: ret={ret}")
                
                if ret == False:
                    # íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
                    print("Playback: ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ë˜ëŠ” íƒ€ì„ì•„ì›ƒ. ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                # í”„ë ˆì„ ë¦¬ì‚¬ì´ì¦ˆ ë° í‘œì‹œ
                frame = cv2.resize(self.frame_ori, dsize=(self.viewers_widget.width(), self.viewers_widget.height()))

                height, width, channels = frame.shape
                # Calculate the number of bytes per line.
                bytes_per_line = width * channels
                self.ImageUpdated.emit(QImage(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB).data, width, height, bytes_per_line, QImage.Format_RGB888))
                
        except Exception as e:
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            tb = traceback.format_exc()
            print(f"Error occurred at {current_time}: {e}\n{tb}", file=sys.stderr)
        finally:
            if self.reader:
                self.reader.stop()
            self.quit()

    def stop(self) -> None:
        self.__thread_active = False
        if self.reader:
            self.reader.stop()
        self.wait()         

class Plot_Camera_Viewer(QLabel):
    clicked = Signal(QPoint)  # ì‚¬ìš©ìê°€ í´ë¦­í•œ ìœ„ì¹˜ë¥¼ ì „ë‹¬í•˜ëŠ” ì‹œê·¸ë„

    def __init__(self, parent=None):
        super().__init__(parent)
        self.point_list = []
        self.non_active_point_list = []
        self.zoom_factor = 1.0  # ì´ˆê¸° í™•ëŒ€ ë°°ìœ¨
        self.offset = QPoint(0, 0)  # í™•ëŒ€/ì¶•ì†Œì˜ ì˜¤í”„ì…‹ì„ ì €ì¥
        self.setScaledContents(True)  # QLabelì´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •ë¨

        # self.setMinimumSize(1, 1)

    def mousePressEvent(self, event):
        if event.button() == Qt.LeftButton:
            self.clicked.emit(event.pos())  # í´ë¦­ ìœ„ì¹˜ë¥¼ emit

        if event.button() == Qt.RightButton:
            self.clicked.emit(QPoint(-1, -1))  # í´ë¦­ ìœ„ì¹˜ë¥¼ emit

    def set_point(self, point_list, img_size = None):
        # self.point_list = [QPoint(int(img_size[0] * point[0]), int(img_size[1] * point[1])) for point in point_list]  # QPoint ê°ì²´ë¡œ ë³€í™˜
        self.point_list = []
        for point in point_list:
            self.point_list.append([point[0], point[1]])
        
        self.update()

    def set_gray_point(self, non_active_point_list, img_size = None):
        self.non_active_point_list = []
        for point_list in non_active_point_list:
            non_point_list = []

            for point in point_list:
                non_point_list.append([point[0], point[1]])

            self.non_active_point_list.append(non_point_list)

            # self.non_active_point_list.append([QPoint(int(img_size[0] * point[0]), int(img_size[1] * point[1])) for point in point_list]  )
            # self.non_active_point_list.append([[point[0], point[1]] for point in point_list])
                                  
        self.update()

    def paintEvent(self, event):
        super().paintEvent(event)

        gray_painter = QPainter(self)
        gray_pen = QPen(QColor(QColor(84,84,84)))
        
        gray_pen.setWidth(5)  # íœì˜ ë‘ê»˜ ì„¤ì •
        gray_painter.setPen(gray_pen)

        fillColor = QColor(84,84,84,127)
        brush = QBrush(fillColor)
        gray_painter.setBrush(brush)

        for gray_point_list in self.non_active_point_list:
            if len(gray_point_list) > 2:
                gray_point_list = [QPoint(int(self.width() * point[0]), int(self.height() * point[1])) for point in gray_point_list]  # QPoint ê°ì²´ë¡œ ë³€í™˜
                gray_polygon = QPolygon(gray_point_list)
                gray_painter.drawPolygon(gray_polygon)
                # gray_painter.drawPolygon([x * self.width(), y * self.height()])  # ì œê³µëœ ì¢Œí‘œì— ì ì„ ê·¸ë¦¼


        painter = QPainter(self)
        pen = QPen(QColor(QColor(83,195,2)))
        
        pen.setWidth(5)  # íœì˜ ë‘ê»˜ ì„¤ì •
        painter.setPen(pen)

        fillColor = QColor(129,215,66,127)
        brush = QBrush(fillColor)
        painter.setBrush(brush)

        for point in self.point_list:
            painter.drawPoint(int(point[0] * self.width()), int(point[1] * self.height()))  # ì œê³µëœ ì¢Œí‘œì— ì ì„ ê·¸ë¦¼
        if len(self.point_list) > 2:
            point_list = [QPoint(int(self.width() * point[0]), int(self.height() * point[1])) for point in self.point_list]  # QPoint ê°ì²´ë¡œ ë³€í™˜
            polygon = QPolygon(point_list)
            painter.drawPolygon(polygon)

    def reset(self):
        self.point_list = []
        self.non_active_point_list = []

        self.update()

    def reset_green_area(self):
        self.point_list = []

        self.update()

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.update()


class FadeOutWindow(QWidget):
    def __init__(self, parent=None, msg="None"):
        super().__init__(parent=parent)
        self.msg = msg
        self.initUI()
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.startFadeOut()

    def initUI(self):
        self.setWindowTitle('Information')
        self.setFixedSize(381, 61)  # ê³ ì • í¬ê¸°
        self.setStyleSheet("background-color: rgba(255, 255, 255, 255); border-radius: 10px;")
        layout = QVBoxLayout()
        layout.setContentsMargins(0, 0, 0, 0)

        self.info_label = QLabel(self.msg, self)
        self.info_label.setObjectName(u"info_label")
        # self.info_label.setGeometry(QRect(0, 0, 381, 61))

        self.info_label.setStyleSheet("background-color: rgb(47, 129, 247); border-radius: 10px; color: white; font-size: 14px;")
        self.info_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.info_label)
        self.setLayout(layout)

        # self.setWindowFlags(Qt.FramelessWindowHint | Qt.Window | Qt.WindowStaysOnTopHint)
        # self.setWindowFlags(Qt.FramelessWindowHint | Qt.Window)
        # self.fadeout_window.setWindowFlags(self.windowFlags() | Qt.WindowStaysOnTopHint)
        self.setWindowFlags(Qt.FramelessWindowHint | Qt.WindowStaysOnTopHint | Qt.Tool)


    def startFadeOut(self):
        QTimer.singleShot(1000, self.fadeOut)

    def fadeOut(self):
        self.anim = QPropertyAnimation(self, b'windowOpacity')
        self.anim.setDuration(1500)
        self.anim.setStartValue(1)
        self.anim.setEndValue(0)
        self.anim.setEasingCurve(QEasingCurve.InOutQuad)
        self.anim.finished.connect(self.close)
        self.anim.start()

class FadeOutInWindow(QWidget):
    def __init__(self, parent=None, camera_name = 0, data = {}, window_num = 0):
        super().__init__(parent=parent)
        now = datetime.now().strftime("%Y/%m/%d %H:%M:%S")
        # print(data)
        self.window_title = f"Alarm {window_num}"
        if len(data):
            self.msg = f"{camera_name} ì¹´ë©”ë¼ : {Eng2kor(data[0])} \n {data[2]}"

        self.initUI()
        self.setAttribute(Qt.WA_TranslucentBackground)
        self.toggleFade()

    def initUI(self):
        self.setWindowTitle(self.window_title)
        self.setFixedSize(381, 61)  # ê³ ì • í¬ê¸°
        self.setStyleSheet("background-color: rgba(255, 255, 255, 255); border-radius: 10px;")
        layout = QVBoxLayout()
        layout.setContentsMargins(0, 0, 0, 0)

        self.info_label = QLabel(self.msg, self)
        self.info_label.setObjectName(u"info_label")
        self.info_label.setStyleSheet("background-color: rgb(53, 132, 228); border-radius: 10px; color: white; font-size: 14px;")
        # self.info_label.setStyleSheet("background-color: rgb(19, 193, 13); border-radius: 10px; color: white; font-size: 14px;")
        
        self.info_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.info_label)
        self.setLayout(layout)

        self.setWindowFlags(Qt.FramelessWindowHint | Qt.Window | Qt.WindowStaysOnTopHint)


    def toggleFade(self):
        self.anim = QPropertyAnimation(self, b'windowOpacity')
        self.anim.setDuration(1500)
        self.anim.setStartValue(1)
        self.anim.setEndValue(0)
        self.anim.setEasingCurve(QEasingCurve.InOutQuad)
        self.anim.finished.connect(self.fadeIn)
        self.anim.start()

    def fadeIn(self):
        self.anim.setStartValue(0)
        self.anim.setEndValue(1)
        self.anim.finished.connect(self.toggleFade)
        self.anim.start()

    def mousePressEvent(self, event: QMouseEvent):
        if event.button() == Qt.LeftButton:
            self.close()  # ì°½ì„ ë‹«ìŠµë‹ˆë‹¤.

def plot_one_box(x, img, color=None, label=None, bbox=None, line_thickness=3):
    # Plots one bounding box on image img
    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness
    color = color or [random.randint(0, 255) for _ in range(3)]
    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))
    if bbox:
        cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)
    if label:
        tf = max(tl - 1, 1)  # font thickness
        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]
        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3
        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled
        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)

def draw_roi(points, image, color, thickness=1, is_closed=True):
    """ ì´ë¯¸ì§€ì— ê´€ì‹¬ ì˜ì—­(ROI)ë¥¼ ê·¸ë¦½ë‹ˆë‹¤. """
    cv2.polylines(image, [np.int32(points)], is_closed, color, thickness)

def TF_detect_area(detect_info, img_size):
    TF_detect_area_list = []
    if len(detect_info):
        if isinstance(detect_info[0], list): 
            for item in detect_info:
                # ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ì˜ ì²« ë²ˆì§¸ ìš”ì†ŒëŠ” ê¸°ì¡´ ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ìœ ì§€
                label = item[0]
                coordinates = item[1:]

                # ì¢Œí‘œì— ëŒ€í•œ ë³€í™˜ ìˆ˜í–‰
                transformed_coordinates = [[int(x[0] * img_size[0]), int(x[1] * img_size[1])] for x in coordinates]
                
                # ë³€í™˜ëœ ì¢Œí‘œë¥¼ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                TF_detect_area_list.append([label] + transformed_coordinates)

        elif isinstance(detect_info[0], str): 
            label = detect_info[0]
            coordinates = detect_info[1:]

            # ì¢Œí‘œì— ëŒ€í•œ ë³€í™˜ ìˆ˜í–‰
            transformed_coordinates = [[int(x[0] * img_size[0]), int(x[1] * img_size[1])] for x in coordinates]
            
            # ë³€í™˜ëœ ì¢Œí‘œë¥¼ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            TF_detect_area_list.append([label] + transformed_coordinates)

    return TF_detect_area_list

def TF_bbox(bbox, ori_imsz=(640, 360), target_imsz=(1920, 1080)):
    # ì›ë³¸ ì´ë¯¸ì§€ì™€ ëª©í‘œ ì´ë¯¸ì§€ì˜ í¬ê¸° ë¹„ìœ¨ ê³„ì‚°
    width_ratio = target_imsz[0] / ori_imsz[0]
    height_ratio = target_imsz[1] / ori_imsz[1]
    
    # ë³€í™˜ëœ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    TF_boxes = []
    
    # ê° ë°”ìš´ë”© ë°•ìŠ¤ì— ëŒ€í•´ ì¢Œí‘œ ë³€í™˜ ìˆ˜í–‰
    for box in bbox:
        if len(box) == 8:
            x1, y1, x2, y2, id, conf, cls, ind  = box  # ì¢Œí‘œ ì¶”ì¶œ
            # ì¢Œí‘œë¥¼ int(ìƒˆë¡œìš´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
            new_x1 = int(x1 * width_ratio)
            new_y1 = int(y1 * height_ratio)
            new_x2 = int(x2 * width_ratio)
            new_y2 = int(y2 * height_ratio)
        
            # ë³€í™˜ëœ ì¢Œí‘œì™€ ê¸°ì¡´ ì •ë³´ë¥¼ í•©ì³ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            TF_boxes.append([new_x1, new_y1, new_x2, new_y2, id, conf, cls, ind])
        
        elif len(box) == 6:
            x1, y1, x2, y2, conf, cls, = box  # ì¢Œí‘œ ì¶”ì¶œ

            # ì¢Œí‘œë¥¼ int(ìƒˆë¡œìš´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
            new_x1 = int(x1 * width_ratio)
            new_y1 = int(y1 * height_ratio)
            new_x2 = int(x2 * width_ratio)
            new_y2 = int(y2 * height_ratio)
            
            # ë³€í™˜ëœ ì¢Œí‘œì™€ ê¸°ì¡´ ì •ë³´ë¥¼ í•©ì³ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            TF_boxes.append([new_x1, new_y1, new_x2, new_y2, conf, cls])

        if len(box) == 9:
                x1, y1, x2, y2, id, conf, cls, ind, status = box  # ì¢Œí‘œ ì¶”ì¶œ
                # ì¢Œí‘œë¥¼ int(ìƒˆë¡œìš´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                new_x1 = int(x1 * width_ratio)
                new_y1 = int(y1 * height_ratio)
                new_x2 = int(x2 * width_ratio)
                new_y2 = int(y2 * height_ratio)
            
                # ë³€í™˜ëœ ì¢Œí‘œì™€ ê¸°ì¡´ ì •ë³´ë¥¼ í•©ì³ ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                TF_boxes.append([new_x1, new_y1, new_x2, new_y2, id, conf, cls, ind, status])
        
    return TF_boxes

def plot_detect_info(img, detect_info, line_thickness = 1 , roi_thickness = 1, plot_bbox = True, plot_label = True, plot_roi = True):
    ROI_color_dict = {"Loitering": [53, 225, 225], "Intrusion": [35, 28, 255], "Fire": [33, 145, 237],
                                "Fight": [255, 0, 127], "Falldown": [230, 255, 121], "Trash": [0, 165, 255]}
    # names = { 0 : "person", 1 : "fire"}
    names = { 0 : "person", 1 : "bicycle", 2 : "car", 3 : "motorcycle", 4 : "bus", 5 : "truck", 6 : "fire"}


    # person_bbox = TF_bbox(detect_info["person_bbox"], ori_imsz=(1280, 720), target_imsz=(img.shape[1], img.shape[0]))
    # non_person_bbox = TF_bbox(detect_info["non_person_bbox"], ori_imsz=(1280, 720), target_imsz=(img.shape[1], img.shape[0]))

    person_bbox = TF_bbox(detect_info["person_bbox"], ori_imsz=(640, 480), target_imsz=(img.shape[1], img.shape[0]))
    non_person_bbox = TF_bbox(detect_info["non_person_bbox"], ori_imsz=(640, 480), target_imsz=(img.shape[1], img.shape[0]))

    for person_box in person_bbox:
        if len(person_box) == 9:
            x1, y1, x2, y2, id, conf, cls, ind, status = person_box
            xyxy = np.array([x1, y1, x2, y2],dtype="int") # float64 to int
            conf = conf
            id = int(id)
            cls = int(cls)

            if plot_label:
                label = f'{id} {names[cls]} {100 * conf:.1f}%'
            else:
                label = False

            if status == 1 :
                bbox_color = (0,75,150)

            elif status == 2 :
                bbox_color = (60,20,220)

            elif status == 0 :
                bbox_color = (0,150,95)

            else:
                bbox_color = COLOR[int(cls)]
                # bbox_color = COLOR(int(cls))

            plot_one_box(xyxy, img, label=label, bbox = plot_bbox, color=bbox_color, line_thickness=line_thickness) # ë°•ìŠ¤ ê·¸ë¦¬ê¸°

        elif len(person_box) == 8:
            x1, y1, x2, y2, id, conf, cls, ind = person_box
            xyxy = np.array([x1, y1, x2, y2],dtype="int") # float64 to int
            conf = conf
            id = int(id)
            cls = int(cls)

            if plot_label:
                label = f'{id} {names[cls]} {100 * conf:.1f}%'
            else:
                label = False

            # bbox_color = COLOR(int(cls))
            bbox_color = COLOR[int(cls)]

            plot_one_box(xyxy, img, label=label, bbox = plot_bbox, color=bbox_color, line_thickness=line_thickness) # ë°•ìŠ¤ ê·¸ë¦¬ê¸°

    for (x1, y1, x2, y2, conf, cls) in non_person_bbox: #fire bbox
        xyxy = np.array([x1, y1, x2, y2],dtype="int") # float64 to int
        conf = conf
        cls = int(cls)

        # bbox_color = (4,19,190)
        bbox_color = COLOR[int(cls)]
        if plot_label:
            label = f'{names[cls]} {100 * conf:.1f}%'
        else:
            label = False

        plot_one_box(xyxy, img, label=label, bbox = plot_bbox, color=bbox_color, line_thickness=line_thickness) # ë°•ìŠ¤ ê·¸ë¦¬ê¸°

    if plot_roi:
        TF_roi_info = TF_detect_area(detect_info["ROI_ori"], img_size=(img.shape[1], img.shape[0]))
        for roi_info in TF_roi_info:
            draw_roi(points = roi_info[1:], 
                        image = img,
                        color = ROI_color_dict[roi_info[0]], 
                        thickness = roi_thickness, 
                        is_closed = True)

    return img

def load_info(host, port, file_name):
    data = {"msg" : {"file_name" : file_name}}

    # receive_data = socket_communication(self.HOST, self.PORT, cmd, on_data_received)
    url = f'http://{host}:{port}/load-info'
    # receive_data = requests.post(url, json=data).json()
    try:
        receive_data = requests.get(url, json=data).json()
    except Exception as e:
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        tb = traceback.format_exc()
        print(f"Error occurred at {current_time}: {e}\n{tb}", file=sys.stderr)
        print(requests.get(url, json=data))
    if receive_data["success"] == True:
        return receive_data["data"]

    else: raise(f"{file_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def save_info(host, port, file_name, info):
    data = {"msg" : {"file_name" : file_name, "info" : info}}
    url = f'http://{host}:{port}/save-info'

    receive_data = requests.put(url, json=data).json()

def Eng2kor(eng):
    if eng == "Intrusion": return "ì¹¨ì…"
    elif eng == "Loitering": return "ë°°íšŒ"
    elif eng == "Falldown": return "ì“°ëŸ¬ì§"
    elif eng == "Fire": return "ë°©í™”"
    elif eng == "Fight": return "ì‹¸ì›€"
    elif eng == "Trash": return "ë¬´ë‹¨íˆ¬ê¸°"


def Kor2eng(kor):
    if kor == "ì¹¨ì…" : return "Intrusion"
    elif kor == "ë°°íšŒ": return "Loitering"
    elif kor == "ì“°ëŸ¬ì§": return "Falldown"
    elif kor == "ë°©í™”": return "Fire"
    elif kor == "ì‹¸ì›€": return "Fight"
    elif kor == "ë¬´ë‹¨íˆ¬ê¸°": return "Trash"


    # gmail_sender = 'diddytpq5@gmail.com'
    # gmail_passwd = 'zqpx escp ebme yjyf'
    # TO = 'ysyang@microsystems.co.kr'

def get_datetime_from_path(path):
    parts = path.split('/')  # ê²½ë¡œë¥¼ '/'ë¡œ ë¶„í• 
    date_time_str = parts[-1].split('_')[0]  # íŒŒì¼ ì´ë¦„ì—ì„œ ì‹œê°„ ë¶€ë¶„ ì¶”ì¶œ ('08.54.48')
    date_str = parts[-3]  # ë‚ ì§œ ë¶€ë¶„ ì¶”ì¶œ ('24.04.29')
    # ë‚ ì§œì™€ ì‹œê°„ ë¬¸ìì—´ ê²°í•©
    full_datetime_str = f"{date_str} {date_time_str}"
    # datetime ê°ì²´ë¡œ ë³€í™˜
    return datetime.strptime(full_datetime_str, "%y.%m.%d %H.%M.%S")

def get_datetime_from_list(list):
    img_base64, camera_name, date, video_time, label_info = list

    return datetime.strptime(date + " " + video_time, "%y-%m-%d %H:%M:%S")


def print_error(e):
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    tb = traceback.format_exc()
    print(f"Error occurred at {current_time}: {e}\n{tb}", file=sys.stderr)

def check_nvidia_gpu():
    try:
        # 'nvidia-smi' ëª…ë ¹ì–´ ì‹¤í–‰
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode == 0:
            print("NVIDIA GPU is available.")
            return True
        else:
            print("NVIDIA GPU is not available.")
            return False

    except FileNotFoundError:
        print("nvidia-smi command not found. No NVIDIA GPU available or drivers not installed.")
        return False


# ----------------------------------------------------------------------
# ì»¤ìŠ¤í…€ ì•Œë¦¼ ì‹œìŠ¤í…œ
# ----------------------------------------------------------------------
class CustomNotification(QWidget):
    """
    ê°œë³„ ì•Œë¦¼ ì°½ì„ ë‹´ë‹¹í•˜ëŠ” ìœ„ì ¯ í´ë˜ìŠ¤.
    ì• ë‹ˆë©”ì´ì…˜, íƒ€ì´ë¨¸, í´ë¦­ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    # ë‹«í ë•Œ ë§¤ë‹ˆì €ì—ê²Œ ì•Œë¦¬ê¸° ìœ„í•œ ì‹œê·¸ë„
    closed = Signal()
    clicked = Signal(dict)  # í´ë¦­ ì‹œ ì•Œë¦¼ ì •ë³´ ì „ë‹¬

    def __init__(self, title, message, notification_data=None, duration=10000, parent=None):
        super().__init__(parent)
        self.duration = duration
        self.notification_data = notification_data  # ì¹´ë©”ë¼ ì´ë¦„, ì‹œê°„ ë“± ì •ë³´ ì €ì¥

        # --- ìœˆë„ìš° ì„¤ì • ---
        self.setWindowFlags(
            Qt.WindowType.FramelessWindowHint |    # í”„ë ˆì„(ì œëª©í‘œì‹œì¤„) ì—†ìŒ
            Qt.WindowType.Tool |                   # íƒœìŠ¤í¬ë°”ì— í‘œì‹œ ì•ˆ í•¨
            Qt.WindowType.WindowStaysOnTopHint   # í•­ìƒ ë‹¤ë¥¸ ì°½ ìœ„ì— í‘œì‹œ
        )
        self.setAttribute(Qt.WidgetAttribute.WA_DeleteOnClose, True) # ë‹«í ë•Œ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œ

        # --- ë ˆì´ì•„ì›ƒ ë° ìœ„ì ¯ ---
        main_layout = QHBoxLayout(self)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)
        
        # ì¢Œì¸¡ accent bar (ìƒ‰ìƒ ê°•ì¡°ì„ )
        self.accent_bar = QLabel()
        self.accent_bar.setFixedWidth(4)
        self.accent_bar.setStyleSheet("background-color: #4A90E2; border-radius: 0px;")
        
        # ì»¨í…ì¸  ì˜ì—­
        content_widget = QWidget()
        content_layout = QHBoxLayout(content_widget)
        content_layout.setContentsMargins(12, 10, 12, 10)
        content_layout.setSpacing(10)
        
        # ì•„ì´ì½˜ ì˜ì—­
        self.icon_label = QLabel("ğŸ””")  # ì•Œë¦¼ ì•„ì´ì½˜
        self.icon_label.setFixedSize(24, 24)
        self.icon_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.icon_label.setStyleSheet("font-size: 18px;")
        
        # í…ìŠ¤íŠ¸ ì˜ì—­
        text_widget = QWidget()
        text_layout = QVBoxLayout(text_widget)
        text_layout.setContentsMargins(0, 0, 0, 0)
        text_layout.setSpacing(4)
        
        self.title_label = QLabel(title)
        self.message_label = QLabel(message)
        self.message_label.setWordWrap(True)
        
        text_layout.addWidget(self.title_label)
        text_layout.addWidget(self.message_label)
        
        # ë‹«ê¸° ë²„íŠ¼
        self.close_button = QLabel("âœ•")
        self.close_button.setFixedSize(20, 20)
        self.close_button.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.close_button.setCursor(Qt.CursorShape.PointingHandCursor)
        self.close_button.mousePressEvent = lambda e: self.fade_out()
        
        # ì»¨í…ì¸  ë ˆì´ì•„ì›ƒì— ì¶”ê°€
        content_layout.addWidget(self.icon_label)
        content_layout.addWidget(text_widget, 1)
        content_layout.addWidget(self.close_button)
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒì— ì¶”ê°€
        main_layout.addWidget(self.accent_bar)
        main_layout.addWidget(content_widget)

        # --- ëª¨ë˜í•œ ìŠ¤íƒ€ì¼ì‹œíŠ¸ (QSS) ---
        self.setStyleSheet("""
                CustomNotification {
                    background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                                                stop:0 #ffffff, stop:1 #fafbfc);
                    border-radius: 12px;
                    border: 1px solid #e1e4e8;
                }
                QLabel {
                    background-color: transparent;
                }
                #title_label {
                    font-size: 13px;
                    font-weight: bold;
                    color: #1a1a1a;
                    letter-spacing: -0.3px;
                }
                #message_label {
                    font-size: 12px;
                    color: #586069;
                    line-height: 1.5;
                }
                #close_button {
                    font-size: 16px;
                    color: #959da5;
                    font-weight: bold;
                }
                #close_button:hover {
                    color: #d73a49;
                }
                #icon_label {
                    color: #4A90E2;
                }
            """)

        # ê°ì²´ ì´ë¦„ ì„¤ì •
        self.title_label.setObjectName("title_label")
        self.message_label.setObjectName("message_label")
        self.close_button.setObjectName("close_button")
        self.icon_label.setObjectName("icon_label")

        # --- ìœ„ì ¯ í¬ê¸° ì„¤ì • ---
        self.setFixedWidth(360) # ì•Œë¦¼ì°½ ë„ˆë¹„
        self.adjustSize() # ë‚´ìš©ì— ë§ê²Œ ë†’ì´ ìë™ ì¡°ì •
        
        # ê·¸ë¦¼ì íš¨ê³¼ë¥¼ ìœ„í•œ ê·¸ë˜í”½ íš¨ê³¼ (ë” ëª¨ë˜í•œ ëŠë‚Œ)
        self.setGraphicsEffect(self._create_shadow_effect())

        # --- ìë™ ë‹«ê¸° íƒ€ì´ë¨¸ ---
        self.timer = QTimer(self)
        self.timer.setSingleShot(True)
        self.timer.timeout.connect(self.fade_out) # ì‹œê°„ì´ ë‹¤ ë˜ë©´ fade_out í˜¸ì¶œ

        # --- ì• ë‹ˆë©”ì´ì…˜ ---
        self.animation_geometry = QPropertyAnimation(self, b"geometry")
        self.animation_geometry.setEasingCurve(QEasingCurve.Type.OutCubic)
        self.animation_geometry.setDuration(400) # 0.4ì´ˆ

        # fade-in ì• ë‹ˆë©”ì´ì…˜ (ë‚˜íƒ€ë‚  ë•Œ)
        self.animation_fade_in = QPropertyAnimation(self, b"windowOpacity")
        self.animation_fade_in.setDuration(300) # 0.3ì´ˆ
        
        # fade-out ì• ë‹ˆë©”ì´ì…˜ (ì‚¬ë¼ì§ˆ ë•Œ)
        self.animation_fade_out = QPropertyAnimation(self, b"windowOpacity")
        self.animation_fade_out.setDuration(300) # 0.3ì´ˆ
        # fade-out ì• ë‹ˆë©”ì´ì…˜ì´ ëë‚˜ë©´ ìœ„ì ¯ì„ ë‹«ìŒ
        self.animation_fade_out.finished.connect(self.close)

    def _create_shadow_effect(self):
        """
        ê·¸ë¦¼ì íš¨ê³¼ë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(20)  # ë¸”ëŸ¬ ë°˜ê²½
        shadow.setXOffset(0)  # X ì˜¤í”„ì…‹
        shadow.setYOffset(4)  # Y ì˜¤í”„ì…‹ (ì•„ë˜ë¡œ)
        shadow.setColor(QColor(0, 0, 0, 60))  # ë°˜íˆ¬ëª… ê²€ì •
        return shadow

    def slide_in(self, target_pos):
        """
        ì•Œë¦¼ì„ í™”ë©´ ë°–ì—ì„œ 'target_pos' ìœ„ì¹˜ë¡œ ìŠ¬ë¼ì´ë“œ ì¸.
        """
        # í¬ê¸° ì¬ê³„ì‚° (ë‚´ìš©ì— ë§ê²Œ)
        self.adjustSize()
        
        # ì‹œì‘ ìœ„ì¹˜ (ëª©í‘œ ìœ„ì¹˜ì—ì„œ ì‚´ì§ ì•„ë˜, ì•½ê°„ì˜ ì˜¤í”„ì…‹ ì¶”ê°€)
        start_x = target_pos.x()
        start_y = target_pos.y() + 100  # ìµœì¢… ìœ„ì¹˜ì—ì„œ 100px ì•„ë˜ì—ì„œ ì‹œì‘
        start_rect = QRect(start_x, start_y, self.width(), self.height())
        
        # ì¢…ë£Œ ìœ„ì¹˜ (ëª©í‘œ ì§€ì )
        end_rect = QRect(target_pos, self.size())

        self.setGeometry(start_rect)
        self.setWindowOpacity(0.0) # íˆ¬ëª…í•˜ê²Œ ì‹œì‘
        self.show() # ìœ„ì ¯ ë³´ì´ê¸°

        # ìœ„ì¹˜ ì• ë‹ˆë©”ì´ì…˜
        self.animation_geometry.setStartValue(start_rect)
        self.animation_geometry.setEndValue(end_rect)
        self.animation_geometry.start()
        
        # í˜ì´ë“œ ì¸ ì• ë‹ˆë©”ì´ì…˜
        self.animation_fade_in.stop()
        self.animation_fade_in.setStartValue(0.0)
        self.animation_fade_in.setEndValue(1.0)
        self.animation_fade_in.start()
        
        # ìë™ ë‹«ê¸° íƒ€ì´ë¨¸ ì‹œì‘ (durationì´ -1ì´ë©´ ìë™ ë‹«ê¸° ì•ˆ í•¨)
        if self.duration > 0:
            self.timer.start(self.duration)

    def move_to(self, target_pos):
        """
        ì•Œë¦¼ì„ í˜„ì¬ ìœ„ì¹˜ì—ì„œ 'target_pos'ë¡œ ë¶€ë“œëŸ½ê²Œ ì´ë™ (ìŠ¤íƒœí‚¹ ì¬ì •ë ¬ìš©)
        """
        # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì• ë‹ˆë©”ì´ì…˜ì´ ìˆë‹¤ë©´ ì¤‘ì§€
        self.animation_geometry.stop()
        
        # ìƒˆ ì´ë™ ì• ë‹ˆë©”ì´ì…˜ ì„¤ì • ë° ì‹œì‘
        self.animation_geometry.setStartValue(self.geometry())
        self.animation_geometry.setEndValue(QRect(target_pos, self.size()))
        self.animation_geometry.start()
        
    def fade_out(self):
        """
        ì•Œë¦¼ì„ ë¶€ë“œëŸ½ê²Œ ì‚¬ë¼ì§€ê²Œ í•¨ (Fade-out).
        """
        self.timer.stop() # í˜¹ì‹œ ëª¨ë¥¼ íƒ€ì´ë¨¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        self.animation_fade_out.setStartValue(1.0)
        self.animation_fade_out.setEndValue(0.0)
        self.animation_fade_out.start()

    def mousePressEvent(self, event):
        """
        ì•Œë¦¼ì„ í´ë¦­í•˜ë©´ ì¦‰ì‹œ ë‹«ê³  í´ë¦­ ì´ë²¤íŠ¸ ì „ë‹¬.
        """
        if event.button() == Qt.MouseButton.LeftButton:
            self.clicked.emit(self.notification_data if self.notification_data else {})
            self.fade_out() # ë‹«ê¸° ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
            event.accept()

    def closeEvent(self, event):
        """
        ìœ„ì ¯ì´ ë‹«í ë•Œ ë§¤ë‹ˆì €ì—ê²Œ ì•Œë¦¼.
        """
        self.closed.emit()
        super().closeEvent(event)


class NotificationManager(QObject):
    """
    ì—¬ëŸ¬ ê°œì˜ CustomNotification ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê´€ë¦¬.
    ì•Œë¦¼ì„ ìƒì„±í•˜ê³ , ìŠ¤íƒœí‚¹(stacking) ë° ì¬ì •ë ¬ì„ ë‹´ë‹¹.
    """
    def __init__(self, on_click_callback=None, parent=None):
        super().__init__(parent)
        self.notifications = [] # í˜„ì¬ í™œì„±í™”ëœ ì•Œë¦¼ ìœ„ì ¯ ëª©ë¡
        self.padding = 10       # ì•Œë¦¼ ê°„ì˜ ì—¬ë°± ë° í™”ë©´ ê°€ì¥ìë¦¬ ì—¬ë°±
        self.on_click_callback = on_click_callback  # ì•Œë¦¼ í´ë¦­ ì‹œ í˜¸ì¶œí•  ì½œë°±

    def show(self, title, message, notification_data=None, duration=10000):
        """
        ìƒˆ ì•Œë¦¼ì„ ìƒì„±í•˜ê³  í‘œì‹œí•©ë‹ˆë‹¤.
        """
        notification = CustomNotification(title, message, notification_data, duration=duration)
        # ì•Œë¦¼ì´ ë‹«í ë•Œ on_notification_closed ìŠ¬ë¡¯ì´ í˜¸ì¶œë˜ë„ë¡ ì—°ê²°
        notification.closed.connect(self.on_notification_closed)
        # ì•Œë¦¼ í´ë¦­ ì‹œ ì½œë°± í˜¸ì¶œ
        if self.on_click_callback:
            notification.clicked.connect(self.on_click_callback)
        
        self.notifications.append(notification) # ëª©ë¡ì— ì¶”ê°€
        self.reposition() # ì•Œë¦¼ ìœ„ì¹˜ ì¬ì •ë ¬

    def on_notification_closed(self):
        """
        ì•Œë¦¼ì´ ë‹«í˜”ì„ ë•Œ í˜¸ì¶œë˜ëŠ” ìŠ¬ë¡¯.
        """
        sender_widget = self.sender() # ì‹œê·¸ë„ì„ ë³´ë‚¸ ìœ„ì ¯ (ë‹«íŒ ì•Œë¦¼)
        
        try:
            self.notifications.remove(sender_widget) # ëª©ë¡ì—ì„œ ì œê±°
        except ValueError:
            # ì´ë¯¸ ì œê±°ë˜ì—ˆê±°ë‚˜ ëª©ë¡ì— ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
            pass
        
        self.reposition() # ë‚˜ë¨¸ì§€ ì•Œë¦¼ ìœ„ì¹˜ ì¬ì •ë ¬

    def reposition(self):
        """
        í™œì„±í™”ëœ ëª¨ë“  ì•Œë¦¼ì˜ ìœ„ì¹˜ë¥¼ ì¬ì¡°ì •í•©ë‹ˆë‹¤.
        í™”ë©´ ìš°ì¸¡ í•˜ë‹¨ì— ì°¨ê³¡ì°¨ê³¡ ìŒ“ì´ë„ë¡ í•©ë‹ˆë‹¤.
        """
        screen_geo = QGuiApplication.primaryScreen().availableGeometry()
        
        # í˜„ì¬ y ìœ„ì¹˜ (í™”ë©´ í•˜ë‹¨ì—ì„œ ì‹œì‘)
        current_y = screen_geo.height() - self.padding
        
        # ëª©ë¡ì˜ ì—­ìˆœìœ¼ë¡œ ìˆœíšŒ (ìµœì‹  ì•Œë¦¼ì´ ë§¨ ì•„ë˜ì— ìœ„ì¹˜)
        for notification in self.notifications:
            # ë†’ì´ ê³„ì‚°ì„ ìœ„í•´ í¬ê¸° ì¡°ì •
            if not notification.isVisible():
                notification.adjustSize()
            
            widget_height = notification.height()
            
            # ì´ ì•Œë¦¼ì´ ìœ„ì¹˜í•  ëª©í‘œ y ì¢Œí‘œ
            target_y = current_y - widget_height
            
            target_x = screen_geo.width() - notification.width() - self.padding
            target_pos = QPoint(target_x, target_y)
            
            # ì•Œë¦¼ì´ ì•„ì§ í‘œì‹œë˜ì§€ ì•Šì•˜ë‹¤ë©´(ìƒˆ ì•Œë¦¼) -> slide_in
            if not notification.isVisible():
                notification.slide_in(target_pos)
            # ì´ë¯¸ í‘œì‹œëœ ì•Œë¦¼ì´ë¼ë©´(ê¸°ì¡´ ì•Œë¦¼) -> move_to
            else:
                notification.move_to(target_pos)

            # ë‹¤ìŒ ì•Œë¦¼ì´ ìŒ“ì¼ y ìœ„ì¹˜ ì—…ë°ì´íŠ¸ (ìœ„ìª½ìœ¼ë¡œ ì´ë™)
            current_y = target_y - self.padding

